from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import requests
import re
import json
import time
from bs4 import BeautifulSoup
import os

# Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ…Ğ¾Ğ´Ğ° Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
}


# Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº URL Ğ´Ğ»Ñ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸
FILTER_URLS = [
    "https://kolesa.kz/cars/?sort_by=add_date-desc",
    "https://kolesa.kz/cars/?sort_by=price-asc",
    "https://kolesa.kz/cars/?sort_by=year.price-desc.asc",
    "https://kolesa.kz/cars/?sort_by=price-desc",
]

# Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ²Ğ½Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ°
data_dir = os.path.abspath(os.path.join(os.getcwd(), "data/unprocessed_json"))
os.makedirs(data_dir, exist_ok=True)



def get_car_links(url, pages=15):
    links = []
    start_page = 2  # ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ ÑĞ¾ 2-Ğ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
    for page in range(start_page, start_page + pages):
        full_url = f"{url}?page={page}"
        response = requests.get(full_url, headers=HEADERS)
        if response.status_code != 200:
            print(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°: {full_url}")
            continue

        soup = BeautifulSoup(response.text, "html.parser")
        found_links = [a["href"] for a in soup.select('a[href^="/cars/"]')]
        links += ["https://kolesa.kz" + link for link in found_links]

        print(f"ğŸ”— Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° {page}: Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(found_links)} ÑÑÑ‹Ğ»Ğ¾Ğº")
        time.sleep(2)

    return links



def get_car_data(url):
    response = requests.get(url, headers=HEADERS)
    if response.status_code != 200:
        return None
    html = response.text
    match = re.search(r"window\.digitalData\s*=\s*({.*?});", html, re.DOTALL)
    if match:
        data = json.loads(match.group(1))
        return data.get("product", {})
    return None


def parse_cars(url, label="filtered", pages=50):
    cars = []
    links = get_car_links(url, pages)
    for i, link in enumerate(links):
        try:
            response = requests.get(link, headers=HEADERS)
            if response.status_code in [403, 429, 503]:
                print(f"ğŸš¨ Ğ¡Ğ°Ğ¹Ñ‚ Ğ·Ğ°Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ» Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ (ĞºĞ¾Ğ´ {response.status_code}). Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ÑÑ.")
                break
            if response.status_code != 200:
                print(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ: {link}, ÑÑ‚Ğ°Ñ‚ÑƒÑ {response.status_code}")
                continue

            car = get_car_data(link)
            if car:
                cars.append(car)

            time.sleep(2)  # Ğ—Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ´Ğ»Ñ Ğ¾Ğ±Ñ…Ğ¾Ğ´Ğ° Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸

        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ {link}: {e}")

    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ¶Ğµ Ğ¿Ñ€Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞµ
    if cars:
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        file_path = os.path.join(data_dir, f"cars_{label}_{timestamp}.json")
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(cars, f, indent=4, ensure_ascii=False)
        print(f"âœ… Ğ¡Ğ¾Ğ±Ñ€Ğ°Ğ½Ğ¾ {len(cars)} Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğ¹! Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ² {file_path}")

    else:
        print("âš ï¸ ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ.")



def parse_new_cars():
    # ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‘Ğ¼ URL Ğ±ĞµĞ· page
    parse_cars("https://kolesa.kz/cars/", label="new", pages=10)


def parse_filtered_cars():
    for url in FILTER_URLS:
        label = url.split("=")[-1]
        parse_cars(url, label=label, pages=20)


default_args = {
    "owner": "temirlan",
    "depends_on_past": False,
    "start_date": datetime(2024, 2, 14),
    "retries": 2,
    "retry_delay": timedelta(minutes=5),
}

dag = DAG(
    "kolesa_car_parser",
    default_args=default_args,
    schedule_interval="0 15 * * *",  # ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ´ĞµĞ½ÑŒ Ğ² 15:00
    catchup=False,
    tags=["kolesa", "parser"]
)

new_cars_task = PythonOperator(
    task_id="parse_new_cars",
    python_callable=parse_new_cars,
    dag=dag
)

filtered_cars_task = PythonOperator(
    task_id="parse_filtered_cars",
    python_callable=parse_filtered_cars,
    dag=dag,
)

new_cars_task >> filtered_cars_task
